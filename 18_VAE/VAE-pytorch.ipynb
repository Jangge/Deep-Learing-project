{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "803ea700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import distributions\n",
    "import os\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69e0df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     # Normalize the images to be -0.5, 0.5\n",
    "     transforms.Normalize(0.5, 1)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "06778433",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = torchvision.datasets.MNIST('data/', download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c5e3f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28 * 28\n",
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "hidden_size = 512\n",
    "latent_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d6f7a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aee7e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    mnist, batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e256da68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  60000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Number of samples: ', len(mnist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4112cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim, hidden_size, latent_size)\n",
    "decoder = Decoder(latent_size, hidden_size, input_dim)\n",
    "\n",
    "vae = VAE(encoder, decoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e5a57726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): Encoder(\n",
      "    (linear1): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (enc_mu): Linear(in_features=512, out_features=8, bias=True)\n",
      "    (enc_log_sigma): Linear(in_features=512, out_features=8, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (linear1): Linear(in_features=8, out_features=512, bias=True)\n",
      "    (linear2): Linear(in_features=512, out_features=784, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "64efac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "85409798",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "697dcaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, latent_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, H)\n",
    "        self.enc_mu = torch.nn.Linear(H, latent_size)\n",
    "        self.enc_log_sigma = torch.nn.Linear(H, latent_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        mu = self.enc_mu(x)\n",
    "        log_sigma = self.enc_log_sigma(x)\n",
    "        sigma = torch.exp(log_sigma)\n",
    "        return torch.distributions.Normal(loc=mu, scale=sigma)\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        # mu = torch.tanh(self.linear2(x))\n",
    "        return F.sigmoid(self.linear2(x))\n",
    "\n",
    "class VAE(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, state):\n",
    "        q_z = self.encoder(state)\n",
    "        z = q_z.rsample()\n",
    "        return self.decoder(z), q_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "13e19d15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -2732636.25 -2733764.25 1127.952880859375\n",
      "1 -2763952.75 -2764994.5 1041.76220703125\n",
      "2 -2834826.5 -2836146.75 1320.203857421875\n",
      "3 -2746087.75 -2747054.0 966.3382568359375\n",
      "4 -2791350.25 -2792410.5 1060.2666015625\n",
      "5 -2762260.0 -2763240.5 980.5943603515625\n",
      "6 -2781321.25 -2782207.0 885.6624755859375\n",
      "7 -2761483.75 -2762442.5 958.6341552734375\n",
      "8 -2861044.75 -2861969.0 924.1393432617188\n",
      "9 -2826138.5 -2827117.75 979.205810546875\n",
      "10 -2819701.5 -2820668.5 966.9071655273438\n",
      "11 -2844188.75 -2845157.25 968.5294799804688\n",
      "12 -2844634.75 -2845560.25 925.5323486328125\n",
      "13 -2822638.25 -2823618.75 980.515625\n",
      "14 -2873436.75 -2874352.75 916.0518798828125\n",
      "15 -2857629.5 -2858460.0 830.5635986328125\n",
      "16 -2875819.0 -2876661.75 842.7885131835938\n",
      "17 -2829526.25 -2830415.5 889.1818237304688\n",
      "18 -2887804.5 -2888700.0 895.4381103515625\n",
      "19 -2840850.75 -2841713.75 863.0498046875\n",
      "20 -2871963.25 -2872825.0 861.8466796875\n",
      "21 -2879090.0 -2879868.0 777.9322509765625\n",
      "22 -2899586.5 -2900390.5 803.8920288085938\n",
      "23 -2854073.25 -2854910.75 837.3919677734375\n",
      "24 -2865630.25 -2866424.5 794.2182006835938\n",
      "25 -2904000.75 -2904819.25 818.544189453125\n",
      "26 -2887099.25 -2887837.25 737.8753662109375\n",
      "27 -2879356.5 -2880101.0 744.5595092773438\n",
      "28 -2920455.25 -2921242.5 787.333740234375\n",
      "29 -2912898.75 -2913721.5 822.6347045898438\n",
      "30 -2908168.25 -2909027.5 859.3148193359375\n",
      "31 -2914578.0 -2915326.25 748.257568359375\n",
      "32 -2869536.0 -2870269.25 733.2321166992188\n",
      "33 -2901376.0 -2902123.5 747.3753662109375\n",
      "34 -2961449.75 -2962341.75 891.95361328125\n",
      "35 -2887781.5 -2888561.0 779.5321044921875\n",
      "36 -2907353.5 -2908046.0 692.4201049804688\n",
      "37 -2849833.75 -2850508.25 674.4154663085938\n",
      "38 -2869210.5 -2869877.5 667.0798950195312\n",
      "39 -2920509.25 -2921124.25 614.9056396484375\n",
      "40 -2933664.25 -2934353.0 688.7161865234375\n",
      "41 -2959575.25 -2960365.0 789.8687744140625\n",
      "42 -2895382.5 -2896059.0 676.3802490234375\n",
      "43 -2911863.5 -2912525.0 661.3978271484375\n",
      "44 -2902012.25 -2902667.5 655.3246459960938\n",
      "45 -2912963.25 -2913591.0 627.8060302734375\n",
      "46 -2922511.25 -2923164.0 652.8515625\n",
      "47 -2891386.0 -2892012.0 626.0673217773438\n",
      "48 -2967901.0 -2968651.0 749.9771728515625\n",
      "49 -2900598.0 -2901270.25 672.176513671875\n",
      "50 -2896837.25 -2897469.0 631.681640625\n",
      "51 -2889229.25 -2889925.0 695.7501220703125\n",
      "52 -2880648.0 -2881185.5 537.464111328125\n",
      "53 -2893808.0 -2894454.0 646.1193237304688\n",
      "54 -2916812.5 -2917471.5 659.0546875\n",
      "55 -2959586.5 -2960255.5 668.919921875\n",
      "56 -2914265.5 -2914905.0 639.39306640625\n",
      "57 -2918734.75 -2919430.0 695.3221435546875\n",
      "58 -2913340.5 -2913984.75 644.220947265625\n",
      "59 -2923811.5 -2924486.0 674.5699462890625\n",
      "60 -2919246.25 -2919856.0 609.7720947265625\n",
      "61 -2953805.5 -2954432.25 626.8383178710938\n",
      "62 -2962297.0 -2962950.25 653.2091674804688\n",
      "63 -2957803.0 -2958429.75 626.75\n",
      "64 -2923945.5 -2924494.5 548.9765014648438\n",
      "65 -2904866.25 -2905370.25 504.10723876953125\n",
      "66 -2918626.75 -2919167.0 540.2098388671875\n",
      "67 -2914291.5 -2914853.0 561.5809326171875\n",
      "68 -2891817.25 -2892461.0 643.831787109375\n",
      "69 -2919237.5 -2919826.0 588.48974609375\n",
      "70 -2941455.25 -2941998.0 542.8155517578125\n",
      "71 -2942077.25 -2942629.25 551.9257202148438\n",
      "72 -2983614.25 -2984182.0 567.693603515625\n",
      "73 -2947209.25 -2947809.75 600.5924682617188\n",
      "74 -2943639.75 -2944189.5 549.6502685546875\n",
      "75 -2974756.75 -2975325.5 568.6597900390625\n",
      "76 -2941189.5 -2941734.5 545.0966796875\n",
      "77 -2954370.75 -2954931.0 560.1806640625\n",
      "78 -2901009.75 -2901502.0 492.1695556640625\n",
      "79 -2948091.75 -2948630.25 538.6209106445312\n",
      "80 -2918797.5 -2919331.5 533.9249267578125\n",
      "81 -2917772.0 -2918375.75 603.6781005859375\n",
      "82 -2898259.25 -2898748.75 489.6236572265625\n",
      "83 -2917603.25 -2918171.5 568.1989135742188\n",
      "84 -3003493.75 -3004044.5 550.637939453125\n",
      "85 -2964727.75 -2965274.5 546.62744140625\n",
      "86 -2988733.25 -2989316.0 582.6823120117188\n",
      "87 -2926435.5 -2926946.5 511.060302734375\n",
      "88 -2921005.25 -2921572.0 566.7417602539062\n",
      "89 -2916806.75 -2917287.75 480.9373779296875\n",
      "90 -2962681.5 -2963235.0 553.38916015625\n",
      "91 -2933374.75 -2933906.5 531.718017578125\n",
      "92 -2946741.25 -2947276.75 535.4012451171875\n",
      "93 -2934435.5 -2934975.0 539.4380493164062\n",
      "94 -2964124.75 -2964712.0 587.2235107421875\n",
      "95 -2965770.25 -2966337.75 567.4150390625\n",
      "96 -2988742.0 -2989292.25 550.3255004882812\n",
      "97 -2983781.25 -2984240.5 459.16314697265625\n",
      "98 -2986602.5 -2987113.75 511.14263916015625\n",
      "99 -2941955.5 -2942452.5 497.065185546875\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        inputs, _ = data\n",
    "        inputs = inputs.view(-1, input_dim).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        p_x, q_z = vae(inputs)\n",
    "        # log_prob(value)是计算value在定义的正态分布（mean,1）中对应的概率的对数，\n",
    "        # 取负对数作为loss，所以对应的概率越大则loss越小，优化降低loss也就是让x对应的概率密度加大\n",
    "        # log_likelihood = p_x.log_prob(inputs).sum(-1).mean() 好像不太好用\n",
    "        log_likelihood  = F.binary_cross_entropy(p_x, inputs, reduction=\"sum\")\n",
    "        kl = - 0.5 * torch.sum(1 + q_z.variance - q_z.mean.pow(2) - q_z.variance.exp())\n",
    "\n",
    "        loss = log_likelihood + kl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        l = loss.item()\n",
    "    print(epoch, l, log_likelihood.item(), kl.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0ea88f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # 保存示例图片\n",
    "    # 生成一个随机张量\n",
    "    z = torch.randn(16, 784).to(device)\n",
    "    # 将模型结果重新调整成批量，通道，大小的形状\n",
    "    out,_ = vae(z)\n",
    "    a = out.view(-1, 1, 28, 28)\n",
    "   # 生成一组样本图象\n",
    "    save_image(a, os.path.join(sample_dir, '3-50测试.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42eecb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5004, -0.5003, -0.4999,  ..., -0.5004, -0.5004, -0.4999],\n",
       "        [-0.5004, -0.5001, -0.4997,  ..., -0.5001, -0.5001, -0.4999],\n",
       "        [-0.5000, -0.4999, -0.4998,  ..., -0.4999, -0.4999, -0.5000],\n",
       "        ...,\n",
       "        [-0.5004, -0.5003, -0.5000,  ..., -0.5005, -0.5005, -0.5000],\n",
       "        [-0.4994, -0.4994, -0.4992,  ..., -0.4996, -0.4996, -0.4995],\n",
       "        [-0.5000, -0.4999, -0.4999,  ..., -0.5001, -0.5001, -0.4999]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303de221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_zzh",
   "language": "python",
   "name": "machine_zzh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
